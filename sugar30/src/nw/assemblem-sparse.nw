
\section{Introduction}

The preferred sparse matrix format for SuperLU (and for Matlab)
is compressed sparse column (CSC).  The compressed sparse column
data structure consists of three pieces:
\begin{itemize}
  \item An array of non-zero matrix values, in column-major order
  \item An array of row indices, parallel to the non-zeros array
  \item An array of $n+1$ \emph{column pointer} indices.
        The $j$th entry of this array gives the index into the
        nonzero array at which the data for column $j$ starts.
	The last entry of the array (which corresponds to no
	column) is the number of nonzeros.  The column pointer indices
	are strictly increasing.  To represent an empty column,
	we would have two adjacent column pointers with the same value.
\end{itemize}

This module is responsible for providing the [[assemble_matrix]] interface
for generating compressed sparse column matrices.


\section{Interface}

<<assemblem-sparse.h>>=
#ifndef ASSEMBLEM_SPARSE_H
#define ASSEMBLEM_SPARSE_H

#include "assemblem.h"

assemble_matrix_t* assembler_sparse_matrix(int n, int nactive);
void    assembler_sparse_csc   (assemble_matrix_t* assembler);
int     assembler_sparse_nnz   (assemble_matrix_t* assembler);
double* assembler_sparse_nzval (assemble_matrix_t* assembler);
int*    assembler_sparse_colptr(assemble_matrix_t* assembler);
int*    assembler_sparse_rowind(assemble_matrix_t* assembler);

#endif /* ASSEMBLEM_SPARSE_H */
@ 

The sparse matrix assembler is created using [[assembler_sparse_matrix]].
Unlike the dense matrix builder, the sparse matrix builder allocates
its own buffer space.  From the time the assembler is created to the time
the [[assemble_sparse_csc]] function is called, the assembler will keep
internal data in a coordinate format.  When [[assembler_sparse_csc]] is
called the first time, the assembler will translate its internal data
into compressed sparse column format.  The assembler can be re-used after
the call to [[assembler_sparse_csc]]; after that, the CSC index
structure will be re-used, but the data will be overwritten.

The assembler only pays attention to contributions with
index from [[0]] to [[nactive-1]]. 

Once the assembler is working in compressed sparse row format,
the routines [[nzval]], [[colptr]], and [[rowind]] access the
fields of the CSC data structure.


\section{Implementation}

<<assemblem-sparse.c>>=
#include <stdlib.h>
#include <assert.h>

#include "dynarray.h"
#include "assemblem-sparse.h"

<<types>>
<<static functions>>
<<functions>>
@ 

\subsection{Sparse matrix representations}

We actually use two representations for the sparse matrix.
We have already discussed the ultimate format into which the
matrices are delivered (compressed sparse column); however,
during the first assembly pass we use a coordinate format.
The coordinate format consists of a list of entries
with row index, column index, and data.  There may be multiple
entries for a single location in the matrix; these contributions
will be summed together.

The coordinate representation is accumulated into the dynamic array
[[Acoord]].  The [[Acoord]] field is valid while [[is_csc]] is zero;
once the matrix has been converted, the [[nzval]], [[rowind]], and
[[colptr]] fields hold the CSC description, [[Acoord]] is destroyed, 
and [[is_csc]] is true.

<<types>>=
typedef struct coord_t {
    int    i;
    int    j;
    double Aij;
} coord_t;

@ 

<<types>>=
typedef struct csc_build_t {
    int         is_csc;
    int         n;
    int         nactive;
    int         nnz;
    dynarray_t  Acoord;
    int*        colptr;
    int*        rowind;
    double*     nzval;
} csc_build_t;

@ 

<<functions>>=
assemble_matrix_t* assembler_sparse_matrix(int n, int nactive)
{
    assemble_matrix_t* assembler = calloc(1, sizeof(*assembler));
    csc_build_t*       self      = calloc(1, sizeof(*self));
    assembler->data = self;

    self->n       = n;
    self->nactive = nactive;
    self->Acoord  = dynarray_create(sizeof(coord_t), 128);

    assembler->assemble = sparse_put;
    assembler->destroy  = sparse_destroy;

    return assembler;
}

@ 

<<static functions>>=
static void sparse_destroy(void* pself)
{
    csc_build_t* self = pself;
    if (self->is_csc) {
	free(self->nzval);
	free(self->rowind);
	free(self->colptr);
    } else {
	dynarray_destroy(self->Acoord);
    }
    free(self);
}

@ 

<<functions>>=
int assembler_sparse_nnz(assemble_matrix_t* assembler)
{
    csc_build_t* self = assembler->data;
    return self->nnz;
}

double* assembler_sparse_nzval (assemble_matrix_t* assembler)
{
    csc_build_t* self = assembler->data;
    return self->nzval;
}

int* assembler_sparse_colptr(assemble_matrix_t* assembler)
{
    csc_build_t* self = assembler->data;
    return self->colptr;
}

int* assembler_sparse_rowind(assemble_matrix_t* assembler)
{
    csc_build_t* self = assembler->data;
    return self->rowind;
}

@ 

\subsection{Assembling into the matrix}

There are two cases for making the local contribution to the matrix.
Either the matrix is still in coordinate form, or it has already
been converted to CSC.

<<static functions>>=
static void sparse_put(void* pself, int* vars, int n, double* local)
{
    csc_build_t* self = pself;
    int i, j;

    if (self->is_csc) {
	<<assemble into CSC>>
    } else {
	<<assemble into coordinate form>>
    }
}

@ 

Adding a new contribution to a matrix in coordinate form is simple.
We just run through the local data and, for each entry whose global
indices lie within the active variable range,
we add an $(i, j, \mathit{data})$ triple to the [[Acoord]] list.

<<assemble into coordinate form>>=
for (j = 0; j < n; ++j) {
    for (i = 0; i < n; ++i) {
	coord_t coord;
	coord.i   = vars[i];
	coord.j   = vars[j];
	coord.Aij = *local++;
	if (coord.i < self->nactive && coord.j < self->nactive)
	    dynarray_append(self->Acoord, &coord);
    }
}
@ 

To add into a matrix that is already in compressed sparse column form,
we figure out where all the in-range entries go and put them there.

<<assemble into CSC>>=
for (j = 0; j < n; ++j) {
    int j_var = vars[j];
    for (i = 0; i < n; ++i) {
	int i_var = vars[i];
	if (i_var < self->nactive && j_var < self->nactive) {
	    <<find the data index of ([[i_var]], [[j_var]])>>
	    self->nzval[k] += *local++;
	} else {
	    local++;
	}
    }
}
@ 

To find the entry we want, we will start at the top of the column and
scan down.  If we run into the end of the column before finding the
right row index, something is wrong (the new contributions do not
match the structure of the old matrix), and we will fail out at the
assertion.

<<find the data index of ([[i_var]], [[j_var]])>>=
int k = self->colptr[j_var];
while (self->rowind[k] < i_var && k < self->colptr[j_var])
     ++k;
assert(self->rowind[k] == i_var && k != self->colptr[j_var]);
@


\subsection{Conversion from coordinate form}

Converting from coordinate form to compressed sparse column format
is straightforward in concept, but it is easy to get lost in details.
Basically, we sort the coordinate entries in column-major order
and then combine the entries that have the same coordinates.
That gives us the nonzero value array and the row index array,
obviously.  At the same time we can keep build the column pointer
array.  In principle, we do this by noticing whenever we start
processing a new column; in practice, we do something trickier.

<<functions>>=
void assembler_sparse_csc(assemble_matrix_t* assembler)
{
    csc_build_t* self       = assembler->data;
    coord_t*     coord      = dynarray_data(self->Acoord);
    int          num_coord  = dynarray_count(self->Acoord);

    int i, j, count;

    <<check if we can convert to CSC>>
    <<sort coordinate entries by column, then row>>
    <<count the number of distinct coordinates>>
    <<allocate space for the CSC representation>>
    <<transfer data to CSC, combining entries for the same coordinates>>
    <<fill in any unfinished column pointers>>

    self->is_csc = 1;
    dynarray_destroy(self->Acoord);
}

@ 

If we have already converted to compressed sparse column format, there
is no point in doing it again.  If there are no entries, we are probably
witnessing a mistake, and we should notify the user.  An assertion is
a fairly brutal way to accomplish this end -- I would definitely prefer
something more polite.

<<check if we can convert to CSC>>=
if (self->is_csc) 
    return;

assert(num_coord != 0);

@

We sort the coordinate entries into column-major order (increasing
in column number, and increasing in row number within a column)
using the standard library implementation of Quicksort.  Beats coding
it ourselves.

<<sort coordinate entries by column, then row>>=
qsort(coord, num_coord, sizeof(coord_t), coord_compare);

@

<<static functions>>=
static int coord_compare(const void* pA, const void* pB)
{
    const coord_t* A = pA;
    const coord_t* B = pB;

    if      (A->j < B->j) return -1;
    else if (A->j > B->j) return  1;
    else if (A->i < B->i) return -1;
    else if (A->i > B->i) return  1;
    else                  return 0;
}

@ 

We want to allocate just enough space to hold the CSC representation.
That means we do not want extra space for repeated contributions to
the same matrix entry.  The [[count]] variable tells us how many
\emph{unique} matrix locations have associated coordinate entries.

<<count the number of distinct coordinates>>=
count = 1;
for (i = 1; i < dynarray_count(self->Acoord); ++i)
     if (coord_compare(&(coord[i]), &(coord[i-1])) != 0)
         ++count;

@ 

<<allocate space for the CSC representation>>=
self->nzval  = calloc( count,             sizeof(double) );
self->colptr = calloc( self->nactive + 1, sizeof(int)    );
self->rowind = calloc( count,             sizeof(int)    );

@ 

Now we get to the ``meat'' of this routine.  The variable [[j]]
tracks the index of the nonzero array we are putting together.
Now we loop through all the coordinate entries, increment
[[j]] when we see that we have started work on a new location
in the matrix, and store the data and row index.

We keep track of the column pointer by observing that if
entry [[j]] is in the $k$th column, then column $k$ must start
at or after index $j+1$.  So whenever we process an element in
column 3, say, we write out that column 4 starts at the next entry.
Since we process the entries in column major order, the last time
we update the column pointer for column for will be when we process
the last entry in column 3.

Note that this procedure can leave ``holes'' when there are columns
with no nonzero entries.

<<transfer data to CSC, combining entries for the same coordinates>>=
j = 0;
for (i = 0; i < num_coord; ++i) {
    if (i != 0 && coord_compare(&(coord[i]), &(coord[i-1])) != 0)
	++j;
    self->nzval [j] += coord[i].Aij;
    self->rowind[j]  = coord[i].i;
    self->colptr[ coord[i].j+1 ] = j + 1;
}
self->nnz = j+1;

@ 

Now we fill in the ``holes'' from columns with no nonzero entries.
If column $k$ is all zeros, then the pointer for column $k+1$ will
never get updated during the above loop, and so it will be zero.
What it \emph{should} be is the start of the previous column plus zero.

<<fill in any unfinished column pointers>>=
for (i = 1; i < self->nactive; ++i) {
    if (self->colptr[i] == 0) {
	self->colptr[i] = self->colptr[i-1];
    }
}
self->colptr[self->nactive] = self->nnz;
@ 

